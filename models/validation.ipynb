{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:53:46.521349Z",
     "start_time": "2023-12-12T17:53:46.268606Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from data.loaders.DataLoader import Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "odict_keys(['model.encoder.conv1.weight', 'model.encoder.bn1.weight', 'model.encoder.bn1.bias', 'model.encoder.bn1.running_mean', 'model.encoder.bn1.running_var', 'model.encoder.bn1.num_batches_tracked', 'model.encoder.layer1.0.conv1.weight', 'model.encoder.layer1.0.bn1.weight', 'model.encoder.layer1.0.bn1.bias', 'model.encoder.layer1.0.bn1.running_mean', 'model.encoder.layer1.0.bn1.running_var', 'model.encoder.layer1.0.bn1.num_batches_tracked', 'model.encoder.layer1.0.conv2.weight', 'model.encoder.layer1.0.bn2.weight', 'model.encoder.layer1.0.bn2.bias', 'model.encoder.layer1.0.bn2.running_mean', 'model.encoder.layer1.0.bn2.running_var', 'model.encoder.layer1.0.bn2.num_batches_tracked', 'model.encoder.layer1.0.conv3.weight', 'model.encoder.layer1.0.bn3.weight', 'model.encoder.layer1.0.bn3.bias', 'model.encoder.layer1.0.bn3.running_mean', 'model.encoder.layer1.0.bn3.running_var', 'model.encoder.layer1.0.bn3.num_batches_tracked', 'model.encoder.layer1.0.downsample.0.weight', 'model.encoder.layer1.0.downsample.1.weight', 'model.encoder.layer1.0.downsample.1.bias', 'model.encoder.layer1.0.downsample.1.running_mean', 'model.encoder.layer1.0.downsample.1.running_var', 'model.encoder.layer1.0.downsample.1.num_batches_tracked', 'model.encoder.layer1.1.conv1.weight', 'model.encoder.layer1.1.bn1.weight', 'model.encoder.layer1.1.bn1.bias', 'model.encoder.layer1.1.bn1.running_mean', 'model.encoder.layer1.1.bn1.running_var', 'model.encoder.layer1.1.bn1.num_batches_tracked', 'model.encoder.layer1.1.conv2.weight', 'model.encoder.layer1.1.bn2.weight', 'model.encoder.layer1.1.bn2.bias', 'model.encoder.layer1.1.bn2.running_mean', 'model.encoder.layer1.1.bn2.running_var', 'model.encoder.layer1.1.bn2.num_batches_tracked', 'model.encoder.layer1.1.conv3.weight', 'model.encoder.layer1.1.bn3.weight', 'model.encoder.layer1.1.bn3.bias', 'model.encoder.layer1.1.bn3.running_mean', 'model.encoder.layer1.1.bn3.running_var', 'model.encoder.layer1.1.bn3.num_batches_tracked', 'model.encoder.layer1.2.conv1.weight', 'model.encoder.layer1.2.bn1.weight', 'model.encoder.layer1.2.bn1.bias', 'model.encoder.layer1.2.bn1.running_mean', 'model.encoder.layer1.2.bn1.running_var', 'model.encoder.layer1.2.bn1.num_batches_tracked', 'model.encoder.layer1.2.conv2.weight', 'model.encoder.layer1.2.bn2.weight', 'model.encoder.layer1.2.bn2.bias', 'model.encoder.layer1.2.bn2.running_mean', 'model.encoder.layer1.2.bn2.running_var', 'model.encoder.layer1.2.bn2.num_batches_tracked', 'model.encoder.layer1.2.conv3.weight', 'model.encoder.layer1.2.bn3.weight', 'model.encoder.layer1.2.bn3.bias', 'model.encoder.layer1.2.bn3.running_mean', 'model.encoder.layer1.2.bn3.running_var', 'model.encoder.layer1.2.bn3.num_batches_tracked', 'model.encoder.layer2.0.conv1.weight', 'model.encoder.layer2.0.bn1.weight', 'model.encoder.layer2.0.bn1.bias', 'model.encoder.layer2.0.bn1.running_mean', 'model.encoder.layer2.0.bn1.running_var', 'model.encoder.layer2.0.bn1.num_batches_tracked', 'model.encoder.layer2.0.conv2.weight', 'model.encoder.layer2.0.bn2.weight', 'model.encoder.layer2.0.bn2.bias', 'model.encoder.layer2.0.bn2.running_mean', 'model.encoder.layer2.0.bn2.running_var', 'model.encoder.layer2.0.bn2.num_batches_tracked', 'model.encoder.layer2.0.conv3.weight', 'model.encoder.layer2.0.bn3.weight', 'model.encoder.layer2.0.bn3.bias', 'model.encoder.layer2.0.bn3.running_mean', 'model.encoder.layer2.0.bn3.running_var', 'model.encoder.layer2.0.bn3.num_batches_tracked', 'model.encoder.layer2.0.downsample.0.weight', 'model.encoder.layer2.0.downsample.1.weight', 'model.encoder.layer2.0.downsample.1.bias', 'model.encoder.layer2.0.downsample.1.running_mean', 'model.encoder.layer2.0.downsample.1.running_var', 'model.encoder.layer2.0.downsample.1.num_batches_tracked', 'model.encoder.layer2.1.conv1.weight', 'model.encoder.layer2.1.bn1.weight', 'model.encoder.layer2.1.bn1.bias', 'model.encoder.layer2.1.bn1.running_mean', 'model.encoder.layer2.1.bn1.running_var', 'model.encoder.layer2.1.bn1.num_batches_tracked', 'model.encoder.layer2.1.conv2.weight', 'model.encoder.layer2.1.bn2.weight', 'model.encoder.layer2.1.bn2.bias', 'model.encoder.layer2.1.bn2.running_mean', 'model.encoder.layer2.1.bn2.running_var', 'model.encoder.layer2.1.bn2.num_batches_tracked', 'model.encoder.layer2.1.conv3.weight', 'model.encoder.layer2.1.bn3.weight', 'model.encoder.layer2.1.bn3.bias', 'model.encoder.layer2.1.bn3.running_mean', 'model.encoder.layer2.1.bn3.running_var', 'model.encoder.layer2.1.bn3.num_batches_tracked', 'model.encoder.layer2.2.conv1.weight', 'model.encoder.layer2.2.bn1.weight', 'model.encoder.layer2.2.bn1.bias', 'model.encoder.layer2.2.bn1.running_mean', 'model.encoder.layer2.2.bn1.running_var', 'model.encoder.layer2.2.bn1.num_batches_tracked', 'model.encoder.layer2.2.conv2.weight', 'model.encoder.layer2.2.bn2.weight', 'model.encoder.layer2.2.bn2.bias', 'model.encoder.layer2.2.bn2.running_mean', 'model.encoder.layer2.2.bn2.running_var', 'model.encoder.layer2.2.bn2.num_batches_tracked', 'model.encoder.layer2.2.conv3.weight', 'model.encoder.layer2.2.bn3.weight', 'model.encoder.layer2.2.bn3.bias', 'model.encoder.layer2.2.bn3.running_mean', 'model.encoder.layer2.2.bn3.running_var', 'model.encoder.layer2.2.bn3.num_batches_tracked', 'model.encoder.layer2.3.conv1.weight', 'model.encoder.layer2.3.bn1.weight', 'model.encoder.layer2.3.bn1.bias', 'model.encoder.layer2.3.bn1.running_mean', 'model.encoder.layer2.3.bn1.running_var', 'model.encoder.layer2.3.bn1.num_batches_tracked', 'model.encoder.layer2.3.conv2.weight', 'model.encoder.layer2.3.bn2.weight', 'model.encoder.layer2.3.bn2.bias', 'model.encoder.layer2.3.bn2.running_mean', 'model.encoder.layer2.3.bn2.running_var', 'model.encoder.layer2.3.bn2.num_batches_tracked', 'model.encoder.layer2.3.conv3.weight', 'model.encoder.layer2.3.bn3.weight', 'model.encoder.layer2.3.bn3.bias', 'model.encoder.layer2.3.bn3.running_mean', 'model.encoder.layer2.3.bn3.running_var', 'model.encoder.layer2.3.bn3.num_batches_tracked', 'model.encoder.layer3.0.conv1.weight', 'model.encoder.layer3.0.bn1.weight', 'model.encoder.layer3.0.bn1.bias', 'model.encoder.layer3.0.bn1.running_mean', 'model.encoder.layer3.0.bn1.running_var', 'model.encoder.layer3.0.bn1.num_batches_tracked', 'model.encoder.layer3.0.conv2.weight', 'model.encoder.layer3.0.bn2.weight', 'model.encoder.layer3.0.bn2.bias', 'model.encoder.layer3.0.bn2.running_mean', 'model.encoder.layer3.0.bn2.running_var', 'model.encoder.layer3.0.bn2.num_batches_tracked', 'model.encoder.layer3.0.conv3.weight', 'model.encoder.layer3.0.bn3.weight', 'model.encoder.layer3.0.bn3.bias', 'model.encoder.layer3.0.bn3.running_mean', 'model.encoder.layer3.0.bn3.running_var', 'model.encoder.layer3.0.bn3.num_batches_tracked', 'model.encoder.layer3.0.downsample.0.weight', 'model.encoder.layer3.0.downsample.1.weight', 'model.encoder.layer3.0.downsample.1.bias', 'model.encoder.layer3.0.downsample.1.running_mean', 'model.encoder.layer3.0.downsample.1.running_var', 'model.encoder.layer3.0.downsample.1.num_batches_tracked', 'model.encoder.layer3.1.conv1.weight', 'model.encoder.layer3.1.bn1.weight', 'model.encoder.layer3.1.bn1.bias', 'model.encoder.layer3.1.bn1.running_mean', 'model.encoder.layer3.1.bn1.running_var', 'model.encoder.layer3.1.bn1.num_batches_tracked', 'model.encoder.layer3.1.conv2.weight', 'model.encoder.layer3.1.bn2.weight', 'model.encoder.layer3.1.bn2.bias', 'model.encoder.layer3.1.bn2.running_mean', 'model.encoder.layer3.1.bn2.running_var', 'model.encoder.layer3.1.bn2.num_batches_tracked', 'model.encoder.layer3.1.conv3.weight', 'model.encoder.layer3.1.bn3.weight', 'model.encoder.layer3.1.bn3.bias', 'model.encoder.layer3.1.bn3.running_mean', 'model.encoder.layer3.1.bn3.running_var', 'model.encoder.layer3.1.bn3.num_batches_tracked', 'model.encoder.layer3.2.conv1.weight', 'model.encoder.layer3.2.bn1.weight', 'model.encoder.layer3.2.bn1.bias', 'model.encoder.layer3.2.bn1.running_mean', 'model.encoder.layer3.2.bn1.running_var', 'model.encoder.layer3.2.bn1.num_batches_tracked', 'model.encoder.layer3.2.conv2.weight', 'model.encoder.layer3.2.bn2.weight', 'model.encoder.layer3.2.bn2.bias', 'model.encoder.layer3.2.bn2.running_mean', 'model.encoder.layer3.2.bn2.running_var', 'model.encoder.layer3.2.bn2.num_batches_tracked', 'model.encoder.layer3.2.conv3.weight', 'model.encoder.layer3.2.bn3.weight', 'model.encoder.layer3.2.bn3.bias', 'model.encoder.layer3.2.bn3.running_mean', 'model.encoder.layer3.2.bn3.running_var', 'model.encoder.layer3.2.bn3.num_batches_tracked', 'model.encoder.layer3.3.conv1.weight', 'model.encoder.layer3.3.bn1.weight', 'model.encoder.layer3.3.bn1.bias', 'model.encoder.layer3.3.bn1.running_mean', 'model.encoder.layer3.3.bn1.running_var', 'model.encoder.layer3.3.bn1.num_batches_tracked', 'model.encoder.layer3.3.conv2.weight', 'model.encoder.layer3.3.bn2.weight', 'model.encoder.layer3.3.bn2.bias', 'model.encoder.layer3.3.bn2.running_mean', 'model.encoder.layer3.3.bn2.running_var', 'model.encoder.layer3.3.bn2.num_batches_tracked', 'model.encoder.layer3.3.conv3.weight', 'model.encoder.layer3.3.bn3.weight', 'model.encoder.layer3.3.bn3.bias', 'model.encoder.layer3.3.bn3.running_mean', 'model.encoder.layer3.3.bn3.running_var', 'model.encoder.layer3.3.bn3.num_batches_tracked', 'model.encoder.layer3.4.conv1.weight', 'model.encoder.layer3.4.bn1.weight', 'model.encoder.layer3.4.bn1.bias', 'model.encoder.layer3.4.bn1.running_mean', 'model.encoder.layer3.4.bn1.running_var', 'model.encoder.layer3.4.bn1.num_batches_tracked', 'model.encoder.layer3.4.conv2.weight', 'model.encoder.layer3.4.bn2.weight', 'model.encoder.layer3.4.bn2.bias', 'model.encoder.layer3.4.bn2.running_mean', 'model.encoder.layer3.4.bn2.running_var', 'model.encoder.layer3.4.bn2.num_batches_tracked', 'model.encoder.layer3.4.conv3.weight', 'model.encoder.layer3.4.bn3.weight', 'model.encoder.layer3.4.bn3.bias', 'model.encoder.layer3.4.bn3.running_mean', 'model.encoder.layer3.4.bn3.running_var', 'model.encoder.layer3.4.bn3.num_batches_tracked', 'model.encoder.layer3.5.conv1.weight', 'model.encoder.layer3.5.bn1.weight', 'model.encoder.layer3.5.bn1.bias', 'model.encoder.layer3.5.bn1.running_mean', 'model.encoder.layer3.5.bn1.running_var', 'model.encoder.layer3.5.bn1.num_batches_tracked', 'model.encoder.layer3.5.conv2.weight', 'model.encoder.layer3.5.bn2.weight', 'model.encoder.layer3.5.bn2.bias', 'model.encoder.layer3.5.bn2.running_mean', 'model.encoder.layer3.5.bn2.running_var', 'model.encoder.layer3.5.bn2.num_batches_tracked', 'model.encoder.layer3.5.conv3.weight', 'model.encoder.layer3.5.bn3.weight', 'model.encoder.layer3.5.bn3.bias', 'model.encoder.layer3.5.bn3.running_mean', 'model.encoder.layer3.5.bn3.running_var', 'model.encoder.layer3.5.bn3.num_batches_tracked', 'model.encoder.layer4.0.conv1.weight', 'model.encoder.layer4.0.bn1.weight', 'model.encoder.layer4.0.bn1.bias', 'model.encoder.layer4.0.bn1.running_mean', 'model.encoder.layer4.0.bn1.running_var', 'model.encoder.layer4.0.bn1.num_batches_tracked', 'model.encoder.layer4.0.conv2.weight', 'model.encoder.layer4.0.bn2.weight', 'model.encoder.layer4.0.bn2.bias', 'model.encoder.layer4.0.bn2.running_mean', 'model.encoder.layer4.0.bn2.running_var', 'model.encoder.layer4.0.bn2.num_batches_tracked', 'model.encoder.layer4.0.conv3.weight', 'model.encoder.layer4.0.bn3.weight', 'model.encoder.layer4.0.bn3.bias', 'model.encoder.layer4.0.bn3.running_mean', 'model.encoder.layer4.0.bn3.running_var', 'model.encoder.layer4.0.bn3.num_batches_tracked', 'model.encoder.layer4.0.downsample.0.weight', 'model.encoder.layer4.0.downsample.1.weight', 'model.encoder.layer4.0.downsample.1.bias', 'model.encoder.layer4.0.downsample.1.running_mean', 'model.encoder.layer4.0.downsample.1.running_var', 'model.encoder.layer4.0.downsample.1.num_batches_tracked', 'model.encoder.layer4.1.conv1.weight', 'model.encoder.layer4.1.bn1.weight', 'model.encoder.layer4.1.bn1.bias', 'model.encoder.layer4.1.bn1.running_mean', 'model.encoder.layer4.1.bn1.running_var', 'model.encoder.layer4.1.bn1.num_batches_tracked', 'model.encoder.layer4.1.conv2.weight', 'model.encoder.layer4.1.bn2.weight', 'model.encoder.layer4.1.bn2.bias', 'model.encoder.layer4.1.bn2.running_mean', 'model.encoder.layer4.1.bn2.running_var', 'model.encoder.layer4.1.bn2.num_batches_tracked', 'model.encoder.layer4.1.conv3.weight', 'model.encoder.layer4.1.bn3.weight', 'model.encoder.layer4.1.bn3.bias', 'model.encoder.layer4.1.bn3.running_mean', 'model.encoder.layer4.1.bn3.running_var', 'model.encoder.layer4.1.bn3.num_batches_tracked', 'model.encoder.layer4.2.conv1.weight', 'model.encoder.layer4.2.bn1.weight', 'model.encoder.layer4.2.bn1.bias', 'model.encoder.layer4.2.bn1.running_mean', 'model.encoder.layer4.2.bn1.running_var', 'model.encoder.layer4.2.bn1.num_batches_tracked', 'model.encoder.layer4.2.conv2.weight', 'model.encoder.layer4.2.bn2.weight', 'model.encoder.layer4.2.bn2.bias', 'model.encoder.layer4.2.bn2.running_mean', 'model.encoder.layer4.2.bn2.running_var', 'model.encoder.layer4.2.bn2.num_batches_tracked', 'model.encoder.layer4.2.conv3.weight', 'model.encoder.layer4.2.bn3.weight', 'model.encoder.layer4.2.bn3.bias', 'model.encoder.layer4.2.bn3.running_mean', 'model.encoder.layer4.2.bn3.running_var', 'model.encoder.layer4.2.bn3.num_batches_tracked', 'model.decoder.blocks.x_0_0.conv1.0.weight', 'model.decoder.blocks.x_0_0.conv1.1.weight', 'model.decoder.blocks.x_0_0.conv1.1.bias', 'model.decoder.blocks.x_0_0.conv1.1.running_mean', 'model.decoder.blocks.x_0_0.conv1.1.running_var', 'model.decoder.blocks.x_0_0.conv1.1.num_batches_tracked', 'model.decoder.blocks.x_0_0.conv2.0.weight', 'model.decoder.blocks.x_0_0.conv2.1.weight', 'model.decoder.blocks.x_0_0.conv2.1.bias', 'model.decoder.blocks.x_0_0.conv2.1.running_mean', 'model.decoder.blocks.x_0_0.conv2.1.running_var', 'model.decoder.blocks.x_0_0.conv2.1.num_batches_tracked', 'model.decoder.blocks.x_0_1.conv1.0.weight', 'model.decoder.blocks.x_0_1.conv1.1.weight', 'model.decoder.blocks.x_0_1.conv1.1.bias', 'model.decoder.blocks.x_0_1.conv1.1.running_mean', 'model.decoder.blocks.x_0_1.conv1.1.running_var', 'model.decoder.blocks.x_0_1.conv1.1.num_batches_tracked', 'model.decoder.blocks.x_0_1.conv2.0.weight', 'model.decoder.blocks.x_0_1.conv2.1.weight', 'model.decoder.blocks.x_0_1.conv2.1.bias', 'model.decoder.blocks.x_0_1.conv2.1.running_mean', 'model.decoder.blocks.x_0_1.conv2.1.running_var', 'model.decoder.blocks.x_0_1.conv2.1.num_batches_tracked', 'model.decoder.blocks.x_1_1.conv1.0.weight', 'model.decoder.blocks.x_1_1.conv1.1.weight', 'model.decoder.blocks.x_1_1.conv1.1.bias', 'model.decoder.blocks.x_1_1.conv1.1.running_mean', 'model.decoder.blocks.x_1_1.conv1.1.running_var', 'model.decoder.blocks.x_1_1.conv1.1.num_batches_tracked', 'model.decoder.blocks.x_1_1.conv2.0.weight', 'model.decoder.blocks.x_1_1.conv2.1.weight', 'model.decoder.blocks.x_1_1.conv2.1.bias', 'model.decoder.blocks.x_1_1.conv2.1.running_mean', 'model.decoder.blocks.x_1_1.conv2.1.running_var', 'model.decoder.blocks.x_1_1.conv2.1.num_batches_tracked', 'model.decoder.blocks.x_0_2.conv1.0.weight', 'model.decoder.blocks.x_0_2.conv1.1.weight', 'model.decoder.blocks.x_0_2.conv1.1.bias', 'model.decoder.blocks.x_0_2.conv1.1.running_mean', 'model.decoder.blocks.x_0_2.conv1.1.running_var', 'model.decoder.blocks.x_0_2.conv1.1.num_batches_tracked', 'model.decoder.blocks.x_0_2.conv2.0.weight', 'model.decoder.blocks.x_0_2.conv2.1.weight', 'model.decoder.blocks.x_0_2.conv2.1.bias', 'model.decoder.blocks.x_0_2.conv2.1.running_mean', 'model.decoder.blocks.x_0_2.conv2.1.running_var', 'model.decoder.blocks.x_0_2.conv2.1.num_batches_tracked', 'model.decoder.blocks.x_1_2.conv1.0.weight', 'model.decoder.blocks.x_1_2.conv1.1.weight', 'model.decoder.blocks.x_1_2.conv1.1.bias', 'model.decoder.blocks.x_1_2.conv1.1.running_mean', 'model.decoder.blocks.x_1_2.conv1.1.running_var', 'model.decoder.blocks.x_1_2.conv1.1.num_batches_tracked', 'model.decoder.blocks.x_1_2.conv2.0.weight', 'model.decoder.blocks.x_1_2.conv2.1.weight', 'model.decoder.blocks.x_1_2.conv2.1.bias', 'model.decoder.blocks.x_1_2.conv2.1.running_mean', 'model.decoder.blocks.x_1_2.conv2.1.running_var', 'model.decoder.blocks.x_1_2.conv2.1.num_batches_tracked', 'model.decoder.blocks.x_2_2.conv1.0.weight', 'model.decoder.blocks.x_2_2.conv1.1.weight', 'model.decoder.blocks.x_2_2.conv1.1.bias', 'model.decoder.blocks.x_2_2.conv1.1.running_mean', 'model.decoder.blocks.x_2_2.conv1.1.running_var', 'model.decoder.blocks.x_2_2.conv1.1.num_batches_tracked', 'model.decoder.blocks.x_2_2.conv2.0.weight', 'model.decoder.blocks.x_2_2.conv2.1.weight', 'model.decoder.blocks.x_2_2.conv2.1.bias', 'model.decoder.blocks.x_2_2.conv2.1.running_mean', 'model.decoder.blocks.x_2_2.conv2.1.running_var', 'model.decoder.blocks.x_2_2.conv2.1.num_batches_tracked', 'model.decoder.blocks.x_0_3.conv1.0.weight', 'model.decoder.blocks.x_0_3.conv1.1.weight', 'model.decoder.blocks.x_0_3.conv1.1.bias', 'model.decoder.blocks.x_0_3.conv1.1.running_mean', 'model.decoder.blocks.x_0_3.conv1.1.running_var', 'model.decoder.blocks.x_0_3.conv1.1.num_batches_tracked', 'model.decoder.blocks.x_0_3.conv2.0.weight', 'model.decoder.blocks.x_0_3.conv2.1.weight', 'model.decoder.blocks.x_0_3.conv2.1.bias', 'model.decoder.blocks.x_0_3.conv2.1.running_mean', 'model.decoder.blocks.x_0_3.conv2.1.running_var', 'model.decoder.blocks.x_0_3.conv2.1.num_batches_tracked', 'model.decoder.blocks.x_1_3.conv1.0.weight', 'model.decoder.blocks.x_1_3.conv1.1.weight', 'model.decoder.blocks.x_1_3.conv1.1.bias', 'model.decoder.blocks.x_1_3.conv1.1.running_mean', 'model.decoder.blocks.x_1_3.conv1.1.running_var', 'model.decoder.blocks.x_1_3.conv1.1.num_batches_tracked', 'model.decoder.blocks.x_1_3.conv2.0.weight', 'model.decoder.blocks.x_1_3.conv2.1.weight', 'model.decoder.blocks.x_1_3.conv2.1.bias', 'model.decoder.blocks.x_1_3.conv2.1.running_mean', 'model.decoder.blocks.x_1_3.conv2.1.running_var', 'model.decoder.blocks.x_1_3.conv2.1.num_batches_tracked', 'model.decoder.blocks.x_2_3.conv1.0.weight', 'model.decoder.blocks.x_2_3.conv1.1.weight', 'model.decoder.blocks.x_2_3.conv1.1.bias', 'model.decoder.blocks.x_2_3.conv1.1.running_mean', 'model.decoder.blocks.x_2_3.conv1.1.running_var', 'model.decoder.blocks.x_2_3.conv1.1.num_batches_tracked', 'model.decoder.blocks.x_2_3.conv2.0.weight', 'model.decoder.blocks.x_2_3.conv2.1.weight', 'model.decoder.blocks.x_2_3.conv2.1.bias', 'model.decoder.blocks.x_2_3.conv2.1.running_mean', 'model.decoder.blocks.x_2_3.conv2.1.running_var', 'model.decoder.blocks.x_2_3.conv2.1.num_batches_tracked', 'model.decoder.blocks.x_3_3.conv1.0.weight', 'model.decoder.blocks.x_3_3.conv1.1.weight', 'model.decoder.blocks.x_3_3.conv1.1.bias', 'model.decoder.blocks.x_3_3.conv1.1.running_mean', 'model.decoder.blocks.x_3_3.conv1.1.running_var', 'model.decoder.blocks.x_3_3.conv1.1.num_batches_tracked', 'model.decoder.blocks.x_3_3.conv2.0.weight', 'model.decoder.blocks.x_3_3.conv2.1.weight', 'model.decoder.blocks.x_3_3.conv2.1.bias', 'model.decoder.blocks.x_3_3.conv2.1.running_mean', 'model.decoder.blocks.x_3_3.conv2.1.running_var', 'model.decoder.blocks.x_3_3.conv2.1.num_batches_tracked', 'model.decoder.blocks.x_0_4.conv1.0.weight', 'model.decoder.blocks.x_0_4.conv1.1.weight', 'model.decoder.blocks.x_0_4.conv1.1.bias', 'model.decoder.blocks.x_0_4.conv1.1.running_mean', 'model.decoder.blocks.x_0_4.conv1.1.running_var', 'model.decoder.blocks.x_0_4.conv1.1.num_batches_tracked', 'model.decoder.blocks.x_0_4.conv2.0.weight', 'model.decoder.blocks.x_0_4.conv2.1.weight', 'model.decoder.blocks.x_0_4.conv2.1.bias', 'model.decoder.blocks.x_0_4.conv2.1.running_mean', 'model.decoder.blocks.x_0_4.conv2.1.running_var', 'model.decoder.blocks.x_0_4.conv2.1.num_batches_tracked', 'model.segmentation_head.0.weight', 'model.segmentation_head.0.bias'])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model_dict = torch.load(\"redweb_resnet_ff.pt\",map_location=torch.device(\"cpu\"))\n",
    "trained_model_dict.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:43:13.195670Z",
     "start_time": "2023-12-12T17:43:13.036576Z"
    }
   },
   "id": "f9ee5b09a2f280e3"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from model_trained import UNet as DepthSense"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:44:08.484516Z",
     "start_time": "2023-12-12T17:44:08.479289Z"
    }
   },
   "id": "4e36c17d9dc20842"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /Users/adi/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n",
      "100%|██████████| 95.8M/95.8M [00:03<00:00, 31.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = DepthSense()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:44:19.293797Z",
     "start_time": "2023-12-12T17:44:15.086249Z"
    }
   },
   "id": "bce5de631b5606a5"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(trained_model_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:44:28.858938Z",
     "start_time": "2023-12-12T17:44:28.768600Z"
    }
   },
   "id": "7d85d5a6439e2285"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "img1 = \"./my_cat1.jpeg\"\n",
    "img2 = \"./my_cat2.jpeg\"\n",
    "img3_should_fail = \"./my_cat3_should_fail.jpeg\"\n",
    "img1 = read_image(img1)\n",
    "rescaler = Rescale((992,896))\n",
    "samples = {\n",
    "    \"mono\":img1,\n",
    "    \"heat\":img1 # we dont have it but we wont use it\n",
    "}\n",
    "rescaled = rescaler(samples)\n",
    "rescaled[\"mono\"]= rescaled[\"mono\"].to(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T18:03:45.371731Z",
     "start_time": "2023-12-12T18:03:45.346369Z"
    }
   },
   "id": "e18bf7e46528cfca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
